<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>Can computers think?</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (http://www.tug.org/tex4ht/)"> 
<meta name="originator" content="TeX4ht (http://www.tug.org/tex4ht/)"> 
<!-- html --> 
<meta name="src" content="computerThink.tex"> 
<link rel="stylesheet" type="text/css" href="computerThink.css"> 
</head><body 
>
   <div class="maketitle">



<h2 class="titleHead">Can computers think?</h2>
<div class="author" ><span 
class="cmr-12">M. Girish</span></div><br />
<div class="date" ><span 
class="cmr-12">September 13, 2019</span></div>
   </div>
   <div 
class="abstract" 
>
<div class="center" 
>
<!--l. 13--><p class="noindent" >
<!--l. 13--><p class="noindent" ><span 
class="cmbx-9">Abstract</span></div>
     <!--l. 14--><p class="indent" >    <span 
class="cmr-9">Thinking is a non-trivial process to make a computer develop one. In</span>
     <span 
class="cmr-9">its true essence thinking is what a </span><span 
class="cmti-9">being </span><span 
class="cmr-9">is capable of. A sophisticated</span>
     <span 
class="cmr-9">process which involves past knowledge and </span><span 
class="cmti-9">free will</span><span 
class="cmr-9">. Experiments involving</span>
     <span 
class="cmr-9">thoughtful actions can be used to differentiate a machine from human.</span>
     <span 
class="cmr-9">Computers cannot spawn a </span><span 
class="cmti-9">thought-process </span><span 
class="cmr-9">like humans.</span>
     <!--l. 16--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-1000"></a><span 
class="cmbx-9">Keywords</span></span>
       <span 
class="cmti-9">artificial intelligence, consciousness, free will, intentionality, neural network,</span>
     <span 
class="cmti-9">thought-process</span>
</div>
<!--l. 19--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">1   </span> <a 
 id="x1-20001"></a>Any form of computation is mechanical and doesn&#8217;t need thinking</h3>
<!--l. 20--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-30001"></a></span>
   <span 
class="cmti-10">If computers can think then what qualities would they express or possess?</span>
<!--l. 22--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-40001"></a></span>
   They would converge to a decision based on experiences and presuppositions.
There would be a bias in its choices for rationality may not always be an
outcome.

<!--l. 24--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-50001"></a></span>
   <span 
class="cmti-10">What is thinking, where does it originate and how does it perpetuate?</span>
<!--l. 26--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-60001"></a></span>
   Thought as a random occurrence in our mind would have a more simpler circuitry
for computers. Can they rewire their thoughts by manipulating the programs
to decide and make choices through their own <span 
class="cmti-10">free will</span>? This process may
not have a finite number of steps. This discussion leads to self awareness
and most importantly <span 
class="cmti-10">consciousness</span>. Consciousness in simpler terms means
self-awareness. The computers becoming self-aware of its existence cannot
happen unless programmed to do so. To program this, a programmer would
have to define cases as to what constitutes consciousness and specify whey
can we arrive at a result to indicate that a being <span 
class="cmti-10">is </span>conscious. This may
not be an exhaustive list and hence a futile attempt in making computers
<span 
class="cmti-10">aware</span>.
<!--l. 29--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-70001"></a></span>
   <span 
class="cmti-10">What is consciousness and how are thoughts related to it?</span>
<!--l. 31--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-80001"></a></span>
   When we say that a computer can think and take actions, we say that it does
with minimal programming or human intervention. It can sense the surroundings
through its sensors, interpret the physical quantities and formulate actions based on
experience.
<!--l. 35--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-90001"></a></span>
   <span 
class="cmti-10">What transforms a layman machine into a thoughtful machine?</span>
<!--l. 37--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-100001"></a></span>
   An example that could be thought here is of a lawn mower. It cuts down grass to
keep a garden tidy. So, a lawn mower operated by a gardener would just cut down
whatever it can get in its way - insects, grass, weed, flowers, anything and everything.
The onus is on the gardener to control its movement and how much time it spends at
a particular location. A further advancement to this machine is - whether it can
operate in a certain area of action without gardener&#8217;s involvement. The
gardener&#8217;s task is only to fix the boundaries for the mower: a geometric 2D
area for the mower to function. The mower is now capable of measuring
distance from its starting point and gauge the area of operation. Also, the
gardener may fix operational hours and just let it be. This mower now operates
under certain program but still cannot make decisions on which grass to cut,
whether to skip any earthworms and mow parts depending on a optimal
path. The mower with an autonomous computer that could think, would
have to think like a gardener. The gardener senses environment around him
and ventures mowing based on external factors such as weather and soil
conditions. The machine would have to rewire and register memories of
new events and pictures of the vegetation around it. It needs to think and
compute surroundings; to not get in contact with any insect or human. What
happens when unknown conditions in environment affects the machine?
Would it know when to stop and restart? Can it make a decision on its own?

Can machine understand and allocate for its own survival and longevity?
Can a machine consider itself as a living being and take action to nurture
itself and avoid conflict with nature for its survival? The neural network of
a machine and its dynamic wiring to make a choice or action depends on
this process of thinking known as a <span 
class="cmti-10">thought-process</span>. It is the key to any
problem solving - by using one&#8217;s experience to pave way for newer solutions.
Only by past solution to similar problems can humans tend to innovate on
solving existing ones. Moreover, after finding a solution how can machine
evaluate and reassess for its correctness without a verification model designed
autonomously?
   <h3 class="sectionHead"><span class="titlemark">2   </span> <a 
 id="x1-110002"></a>Turing test and its effectiveness</h3>
<!--l. 56--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-120002"></a></span>
   <span 
class="cmti-10">Is the Turing test</span><span class="cite"><span 
class="cmti-10">[</span><a 
href="#Xturing50"><span 
class="cmti-10">1</span></a><span 
class="cmti-10">]</span></span> <span 
class="cmti-10">meaningful and valid?</span>
<!--l. 58--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-130002"></a></span>
   Turing suggested that if a computer and a human being were hidden behind a
screen, and another human being were given the task of interrogating each of them, it
would be reasonable to conclude that the computer was conscious if the interrogator
could not distinguish it from the human being. There have been many variations of
the Turing test proposed, some by Turing himself, and there are annual contests
based on Turing test. Thus far, no computer has passed the Turing test
(by general consensus), although some have come close. Several plausible
characteristics have been proposed &#8212; free will, restricted access (only the
thinker experiences his thoughts), incorrigibility (only the thinker knows with
certainty the content of his thought), qualia (raw sensory experience), etc.
<hr class="figure"><div class="figure" 
>

<a 
 id="x1-130011"></a>

<!--l. 65--><p class="noindent" >
<br /> <div class="caption" 
><span class="id">Figure&#x00A0;1: </span><span  
class="content">The &#8220;standard interpretation&#8221; of the Turing Test, in which player C,
the interrogator, is given the task of trying to determine which player - A or B
- is a computer and which is a human. The interrogator is limited to using the
responses to written questions to make the determination. Image adapted from
Saygin, 2000<span class="cite">[<a 
href="#Xsaygin00">4</a>]</span></span></div><!--tex4ht:label?: x1-130011 -->

<!--l. 67--><p class="indent" >   </div><hr class="endfigure">
   <h3 class="sectionHead"><span class="titlemark">3   </span> <a 
 id="x1-140003"></a>Intentionality behind computation</h3>
<!--l. 70--><p class="noindent" ><span class="paragraphHead"><a 
 id="x1-150003"></a></span>
   The classic argument that computation inherently lacks intentionality (meaning)
can be inferred from Searle&#8217;s Chinese Room analogy <span class="cite">[<a 
href="#Xsearle80">3</a>]</span>. Intentionality is a primary
characteristic of human mind. The actions are driven by it and thoughts
are the fuel. In case of a computer, it manifests the intentionality of its
programmer. The programmer could be another program recursively. Yet, the
base program would be the one of a human programmer. So it derives the
intentionality from a human in principle. Searle concludes through his analogy that
computation has no intrinsic intentionality, but only secondary intentionality
imparted by programmers. Computation is not <span 
class="cmti-10">thinking</span>, but a mechanical
process.
   <h3 class="likesectionHead"><a 
 id="x1-160003"></a>References</h3>
<!--l. 72--><p class="noindent" >
   <div class="thebibliography">
   <p class="bibitem" ><span class="biblabel">
 [1]<span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span><a 
 id="Xturing50"></a>A.M Turing, <span 
class="cmti-10">Computing Machinery and Intelligence, Mind</span>, Volume LIX,
   Issue 236, October 1950, Pages 433&#8211;460
   </p>
   <p class="bibitem" ><span class="biblabel">
 [2]<span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span><a 
 id="Xegnor11"></a>Michael Egnor, <span 
class="cmti-10">Can a Computer Think?</span>, Evolution News, March 2011
   </p>
   <p class="bibitem" ><span class="biblabel">
 [3]<span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span><a 
 id="Xsearle80"></a>Searle,  John.  R.  <span 
class="cmti-10">Minds, brains, and programs. Behavioral and Brain</span>
   <span 
class="cmti-10">Sciences</span>, 3 (3): 417-457
   </p>
   <p class="bibitem" ><span class="biblabel">
 [4]<span class="bibsp">&#x00A0;&#x00A0;&#x00A0;</span></span><a 
 id="Xsaygin00"></a>Saygin, A.P.; Cicekli, I.; Akman, V. <span 
class="cmti-10">Turing Test: 50 Years Later, Minds</span>
   <span 
class="cmti-10">and Machines</span>, 10 (4): 463-518
</p>
   </div>
    
</body></html> 



